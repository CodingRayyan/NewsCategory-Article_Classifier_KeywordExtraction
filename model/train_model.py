# -*- coding: utf-8 -*-
"""Uni Project #1-News Classification Model (NLP_TFIDF) (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t8fISVMVC2N81CN19aLUJzuE8anCwX2o

<br>
<h1 style="text-align: center; font-family: arial black; color: red"><b></b>AI Domain: Natural Language Processing (NLP)<b></b></h1>
<h2 style="text-align: center; color: red"><b>Project: News Headline Classifier using TF-IDF<b></h2>
<br>

<h4 style = "text-align: left; color: red">Start Date: 15 March, 2025</h4>
<h4 style = "text-align: left; color: red">End Date: 18 March, 2025</h4>
<h4 style = "text-align: left; color: red">Submitted to: Engr. Bushra Shaikh</h4>

<br>

<h3 style="text-align: center;"><b>Group Members<b></h3>

<table style="width: 100%; border-collapse: collapse; text-align: left;">
  <thead>
    <tr style="background-color: yellow; color: black">
      <th style="border: 1px solid #ddd; padding: 8px; text-align: center;">Name</th>
      <th style="border: 1px solid #ddd; padding: 8px; text-align: center;">ID</th>
    </tr>
  </thead>
  <tbody>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Rayyan Ahmed</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">22F-BSAI-11</td>
    </tr>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Wajahat Tariq</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">22F-BSAI-17</td>
    </tr>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Muhammed Sami</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">22F-BSAI-43</td>
    </tr>
  </tbody>
</table>

<br>

# ________________________________________________________________________________________
<br>

<h3 style="text-align: center;"><b>Project Idea<b></h3>

<br>

- **Load Data:** Import the dataset using Pandas and read it into a DataFrame.
- **Clean Data:** Remove duplicates, null values, special characters, stopwords, and apply text preprocessing like stemming or lemmatization.
- **Visualize Data:** Analyze category distributions, generate word clouds, and plot frequent words using bar charts.
- **Vectorize Data:** Convert text into numerical format using TF-IDF Vectorizer and experiment with n-grams.
- **Extract Keywords:** Identify important words from headlines using TF-IDF scores.
- **Pipeline Module-Predict Using ML Algorithms:** Through Pipeline Module, train six different algorithms like Logistic Regression, SVM, AdaBoost, NaÃ¯ve Bayes, KNN, Decision Tree Classifier.
- **Save Best Model:** Choose the model with the highest accuracy and save it using joblib or pickle.
- **Deploy Model:** Build a web app using Streamlit or FastAPI and deploy it on a cloud platform like AWS, Azure, or Render. ðŸš€

<br>

# ________________________________________________________________________________________
<br>

<h3 style="text-align: center;"><b>Problem Statement</b></h3>

<br>

- In the digital era, vast amounts of news articles are published daily, making it challenging to categorize and analyze news efficiently. Traditional methods of manual classification are time-consuming and prone to errors. This project aims to build an automated **News Headline Classifier** using **TF-IDF** and machine learning algorithms to categorize news headlines accurately.  

- The project involves **loading, cleaning, visualizing, and vectorizing text data**, extracting **important keywords**, and **training multiple machine learning models** to identify the best-performing algorithm. The most accurate model will be saved and deployed using **Streamlit or FastAPI**, allowing users to input news headlines and receive real-time predictions. The final deployment on **cloud platforms like AWS, Azure, or Render** will enable accessibility and scalability for real-world applications.  

- This solution can be utilized in various domains such as **news aggregation platforms, fake news detection, content recommendation systems, and social media monitoring**, ensuring faster and more reliable news classification.  

<br>

# ________________________________________________________________________________________

<br>

<h3 style="text-align: center;"><b>Python Libraries Used</b></h3>

<table style="width: 100%; border-collapse: collapse; text-align: left;">
  <thead>
    <tr style="background-color: yellow; color: black">
      <th style="border: 1px solid #ddd; padding: 8px; text-align: center;">Library</th>
      <th style="border: 1px solid #ddd; padding: 8px; text-align: center;">Purpose</th>
    </tr>
  </thead>
  <tbody>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Numpy</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">Array handling & manipulation, series controlling</td>
    </tr>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Pandas</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">DataFrame Handling, manipulation and cleaning</td>
    </tr>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Matplotlib & Seaborn</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">Data Visualization, Plotting and showing trends</td>
    </tr>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Plotly</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">3D Visualization of data</td>
    </tr>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Scikit-Learn</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">ML modeling, preprocessing, feature selection, evaluation</td>
    </tr>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">Pipeline Module</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">Making a pipeline, training and predicting our targets on multiple ML Algorithms</td>
    </tr>
    <tr style="background-color: gray;">
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center">joblib</td>
      <td style="border: 1px solid #ddd; padding: 8px; text-align: center;">For saving and loading best algorithm and tf-idf vectorizer</td>
    </tr>
  </tbody>
</table>

<br>

# Let's start our project

<br>

<br>

<h1 style="text-align: center;"><b></b>Loading Our DataSet<b></b></h1>

<br>
"""

import pandas as pd

df = pd.read_csv("NewsCategorizer21.csv")
df.tail()

"""<br>

<h1 style="text-align: center; color: red"><b>1. Analyzing Dataset<b></h1>

- Pandas
    
<br>

<br>

<h2 style="text-align: center;"><b></b>DataSet Info<b></b></h2>

<br>
"""

df.info()

"""<br>

<h2 style="text-align: center;"><b></b>Droping Null Values<b></b></h2>

<br>
"""

df.isnull().sum()

df.dropna(inplace = True)

df.isnull().sum()

"""<br>

<h2 style="text-align: center;"><b></b>DataSet Details<b></b></h2>

<br>
"""

df.columns

df.keys()

df.category

"""<br>

<h2 style="text-align: center;"><b></b>DataSet Description<b></b></h2>

<br>
"""

df.describe()

"""<br>

<h2 style="text-align: center;"><b></b>DataSet Values<b></b></h2>

- Checking the occurences of each category

<br>
"""

print(f"There are total {len(df['category'].value_counts())} news categories.")

df['category'].value_counts()

"""<br>

<h1 style="text-align: center; color: red"><b>2. Visualizing DataSet<b></h1>

- Matplotlib
- Seaborn
    
<br>

<br>

<h2 style="text-align: center;"><b></b>Plotting Pie Plot<b></b></h2>

- Visualizing Category Distribution through Pie Plot

<br>
"""

import matplotlib.pyplot as plt
import seaborn as sns

df['category'].value_counts().plot(kind = 'pie', autopct = '%1.3f%%', figsize = (7, 7), shadow = True, explode = (0.3, 0.08, 0.3, 0.08, 0.08, 0.3, 0.08, 0.08))
plt.title('Category Distribution')
plt.show()

"""<br>

<h2 style="text-align: center;"><b></b>Bar Plot<b></b></h2>

- Plotting Bar Plot for Category Distrbution

<br>
"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 5))
sns.countplot(x=df['category'], order=df['category'].value_counts().index)
plt.title("Category Distribution")
plt.xlabel("Category")
plt.ylabel("Count")
plt.xticks(rotation = 45)
plt.yticks(rotation = 0)
plt.grid(color = 'black')
plt.show(block = True)

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(9, 3))
sns.set_style("darkgrid")

ax = sns.countplot(
    x=df['category'],
    order=df['category'].value_counts().index,
    palette="viridis",
    edgecolor="black"
)

plt.xticks(rotation=45, ha="right", fontsize=12)

# Add labels and title
plt.xlabel("Category", fontsize=14, fontweight="bold", color="darkblue")
plt.ylabel("Count", fontsize=14, fontweight="bold", color="darkblue")
plt.title("Distribution of News Categories", fontsize=16, fontweight="bold", color="darkred")

for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}',
                (p.get_x() + p.get_width() / 2, p.get_height()),
                ha='center', va='bottom', fontsize=12, color="black", fontweight="bold")

plt.grid(color = 'black')
plt.show(block = True)

"""<br>

<h2 style="text-align: center;"><b>Bar Plot</b>Bar Plot<b></b></h2>

- Displaying Top Keywords

<br>
"""

from collections import Counter
keywords = " ".join(df['keywords']).split("-")
top_keywords = dict(Counter(keywords).most_common(15))

plt.figure(figsize=(12,6))
sns.barplot(x=list(top_keywords.keys()), y=list(top_keywords.values()), palette="magma")
plt.xticks(rotation=45)
plt.xlabel("Keywords")
plt.ylabel("Frequency")
plt.title("Top 15 Most Frequent Keywords")
plt.show(block = True)

"""<br>

<h2 style="text-align: center;"><b>Histogram Plot</b>Bar Plot<b></b></h2>

- Displaying Length of Descriptions

<br>
"""

df["desc_length"] = df["short_description"].str.len()
plt.figure(figsize=(12,6))
sns.histplot(df["desc_length"], bins=30, kde=True, color="blue")
plt.xlabel("Description Length")
plt.ylabel("Count")
plt.title("Distribution of Short Description Lengths")
plt.show(block = True)

"""<br>

<h2 style="text-align: center;"><b>Box Plot</b>Bar Plot<b></b></h2>

- Displaying Length of Descriptions across Categories

<br>
"""

plt.figure(figsize=(14,6))
sns.boxplot(x=df["category"], y=df["desc_length"], palette="Set2")
plt.xticks(rotation=45)
plt.xlabel("Category")
plt.ylabel("Description Length")
plt.title("Short Description Length by Category")
plt.show(block = True)

"""<br>
<h1 style="text-align: center; color: red"><b>3. Creating Training and Test DataSet<b></h1>
    
- Scikit-Learn

<br>
"""

x = df['headline']
y = df['category']

"""<br>

<h2 style="text-align: center;"><b>"x (independent variable) info" & "y (dependent variable) info"</b></h2>

<br>
"""

x.info()

y.info()

"""<br>

<h2 style="text-align: center;"><b>Splitting Data into Train & Test Split</b></h2>

<br>
"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)

"""<br>

<h2 style="text-align: center;"><b>Splitted DatSet Shapes</b></h2>

<br>
"""

x_train.shape, x_test.shape, y_train.shape, y_test.shape

"""<br>
<h1 style="text-align: center; color: red"><b>4. Starting Vectorization through TF-IDF<b></h1>
    
- Scikit-Learn
- TF-IDF

<br>

<br>

<h2 style="text-align: center;"><b>Importing Tfidf Vectorizer</b></h2>

<br>
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer()
tfidf

"""<br>

<h2 style="text-align: center;"><b>Fitting & Transforming on Tfidf Vectorizer</b></h2>

<br>
"""

x_train_vec = tfidf.fit_transform(x_train)
x_test_vec = tfidf.transform(x_test)

"""<br>

<h2 style="text-align: center;"><b>x_train & x_test after Fitting & Transforming on Tfidf Vectorizer</b></h2>

<br>
"""

print(x_train_vec)

print(x_test_vec)

"""<br>

<h2 style="text-align: center;"><b>Shape of x_train_vec and x_test_vec and no. of Vocabulary</b></h2>

<br>
"""

print(f"Shape of x_train_tfidf: {x_train_vec.shape},\nShape of x_test_tfidf: {x_test_vec.shape}")

vocab_size = x_train_vec.shape[1]

print(f"\nThere are {x_train_vec.shape[0]} samples in x_train_tfidf and {x_test_vec.shape[0]} samples in x_test_tfidf.")
print(f"Our vocabulary contains {vocab_size} unique words (features).")

"""<br>

<h2 style="text-align: center;"><b>x_train_vec to numpy array</b></h2>

<br>
"""

x_train_vec.toarray()

"""<br>
<h1 style="text-align: center; color: red"><b>5. Importing and Creating our PipeLine Module<b></h1>

- PipeLine Module
    
<h3 style="text-align: center; color: red"><b>Fitting & Predicting on PipeLine of 7 Machine Learning Algorithms<b></h3>

| ML Algorithms |
|:--------|
| 1. Logistic Regression (LogReg)|
| 2. Support Vector Machine (SVM)|
| 3. Naive Bayes Classifier (NBC)|
| 4. K-Nearest Neighbour (KNN)|
| 5. Decision Tree Classifier (DTC) |
| 6. Adaptive Boost (AdaBoost) |


<br>

<br>

<h2 style="text-align: center;"><b>Loading Machine Learning Algorithms</b></h2>

<br>
"""

from sklearn.pipeline import make_pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

"""<br>

<h2 style="text-align: center;"><b>Creating Pipeline of 6 Different ML Algorithms</b></h2>

<br>
"""

models = {
    "NaÃ¯ve Bayes": MultinomialNB(),
    "Logistic Regression": LogisticRegression(max_iter=1200),
    "Linear SVC": LinearSVC(max_iter=2000),
    "Decision Tree": DecisionTreeClassifier(class_weight="balanced"),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "AdaBoost": AdaBoostClassifier(
        estimator=DecisionTreeClassifier(max_depth=1, class_weight="balanced"),
        n_estimators=100,
        learning_rate=0.5
    ),
}

"""<br>

<h2 style="text-align: center;"><b>Fitting & Predicting Data on Algorithms</b></h2>

<br>
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

accuracies = {}
num = 1

for name, model in models.items():
    print(f"\n{'_' * 50} {num}. Training {name} {'_' * 50}")
    num += 1

    pipeline = make_pipeline(model)

    pipeline.fit(x_train_vec, y_train)
    y_pred = pipeline.predict(x_test_vec)
    acc = accuracy_score(y_test, y_pred) * 100
    accuracies[name] = acc

    print(f"\n{name} Predictions: \n{y_pred}")
    print(f"\n{name} Accuracy Score: {acc:.3f} %")
    print(f"\n{name} Classification Report:\n{classification_report(y_test, y_pred)}")

    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)

    plt.figure(figsize=(8, 6))
    disp.plot(cmap="Blues", values_format="d")
    plt.title(f"Confusion Matrix for {name}")
    plt.xticks(rotation = 90)
    plt.show()

"""<br>

<h2 style="text-align: center;"><b>Creating DataFrame of Model with their Respective Accuracies</b></h2>

<br>
"""

import pandas as pd

accuracy_df = pd.DataFrame(list(accuracies.items()), columns=["Model Name", "Model Accuracy"])

accuracy_df = accuracy_df.sort_values(by="Model Accuracy", ascending=False)

accuracy_df.reset_index(drop=True, inplace=True)

accuracy_df

"""#### Hence Linear SVC is the best model in this case, with an overall accuracy of 82.572669"""

linsvc = LinearSVC()
linsvc.fit(x_train_vec, y_train)
y_pred = linsvc.predict(x_test_vec)
print(classification_report(y_test, y_pred))

"""<br>
<h1 style="text-align: center; color: red"><b>6. Extracting Keywords<b></h1>
<br>
"""

askdata = str(input("Wanna extract words from x_train_vec (a) or x_test_vec (b), a or b?: "))
ask = int(input('Enter Sentence Index: '))

feature_names = tfidf.get_feature_names_out()

if askdata == 'a':
    word_indices = x_train_vec[ask].indices
    words_in_doc = [(i, feature_names[i]) for i in word_indices]

    print(f"\nOriginal Sentence of x_train: \n{x_train.iloc[ask]}")
    print(f"\nExtracted Words in Sentence with index {ask} of {askdata}: \n{words_in_doc}")
    for idx, word in words_in_doc:
        print(f"\nWord: {word}  (Vocab Index: {idx})")

elif askdata == 'b':
    word_indices = x_test_vec[ask].indices
    words_in_doc = [(i, feature_names[i]) for i in word_indices]

    print(f"\nOriginal Sentence of x_test: \n{x_test.iloc[ask]}")
    print(f"\nExtracted Words in Sentence with index {ask} of {askdata}: \n{words_in_doc}")
    for idx, word in words_in_doc:
        print(f"\nWord: {word}  (Vocab Index: {idx})")

else:
    print("\nInvalid Input\nEnter x_train_vec or x_test_vec")

"""<br>

<h2 style="text-align: center;"><b>Enter News Headline and Get Category</b></h2>

<br>
"""

print(f"Categories Available: {list(y_train.value_counts().index)}")
sentence = str(input("Enter sentence: "))
headline = tfidf.transform([sentence])
sent_pred = linsvc.predict(headline)

print(f"\nHeadline: {sentence}")
print(f"Category: {sent_pred[0]}")

"""<br>
<h1 style="text-align: center; color: red"><b>7. Saving & Loading Model & Vectorizer<b></h1>
<br>

<br>

<h2 style="text-align: center;"><b>Saving Model</b></h2>

- pickle

<br>
"""

import pickle

with open("newsclassifier_model.pkl", "wb") as model_file:
    pickle.dump(linsvc, model_file)

with open("tfidf_vec.pkl", "wb") as tfidf_file:
    pickle.dump(tfidf, tfidf_file)

print("Model and TF-IDF vectorizer saved successfully!")

"""<br>

<h2 style="text-align: center;"><b>Verifying Data on Loaded Model and Vectorizer</b></h2>

<br>
"""

import pickle

with open("newsclassifier_model.pkl", "rb") as model_file:
    load_linsvc = pickle.load(model_file)

with open("tfidf_vec.pkl", "rb") as tfidf_file:
    tfidf_vec = pickle.load(tfidf_file)

print("Model and TF-IDF vectorizer loaded successfully!")

y_pred_load = load_linsvc.predict(x_test_vec)
y_pred_load

print(classification_report(y_test, y_pred_load))

"""<br>
<h1 style="text-align: center; color: red"><b>8. Model Deployment<b></h1>

- streamlit

### For Model Deployment, follow the following steps:

- Create a python file on another platform i.e: 111743.py
- Create streamlit webpage on that file and run it
- Activate python envoirment through anaconda prompt
- Move to desired directory

<br>
"""







